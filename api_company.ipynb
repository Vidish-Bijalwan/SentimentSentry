{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abf0dc3-21f5-4a21-ad86-c6d12794c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2624acb3-15ac-4a62-b16b-4c513dd26e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     30\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m---> 31\u001b[0m     companies \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m companies:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo more data on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Stopping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# API Configuration\n",
    "url = \"https://clutch-co-scraper1.p.rapidapi.com/\"\n",
    "headers = {\n",
    "    \"x-rapidapi-key\": \"29176455d0msh76cff296476b1c5p160124jsn18fe314a32b4\",\n",
    "    \"x-rapidapi-host\": \"clutch-co-scraper1.p.rapidapi.com\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Initialize dataset storage\n",
    "all_companies = []\n",
    "max_pages = 10  # Adjust this based on the number of results available\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(1, max_pages + 1):\n",
    "    print(f\"Fetching page {page}...\")\n",
    "    \n",
    "    payload = {\n",
    "        \"api_type\": \"search\",\n",
    "        \"search_term\": \"web design\",\n",
    "        \"page\": str(page)\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        companies = data.get(\"results\", [])\n",
    "        \n",
    "        if not companies:\n",
    "            print(f\"No more data on page {page}. Stopping.\")\n",
    "            break  # Stop if no more data is returned\n",
    "        \n",
    "        all_companies.extend(companies)  # Add new data\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error on page {page}: {response.status_code}\")\n",
    "        break  # Stop on error\n",
    "\n",
    "    time.sleep(1)  # Prevent hitting API rate limits\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_companies)\n",
    "\n",
    "# Selecting important columns (Modify based on actual response structure)\n",
    "columns_to_keep = ['company_name', 'rating', 'review_count', 'location', 'services', 'website']\n",
    "df = df[columns_to_keep] if all(col in df.columns for col in columns_to_keep) else df\n",
    "\n",
    "# Save dataset\n",
    "df.to_csv(\"clutch_web_design_companies_large.csv\", index=False)\n",
    "\n",
    "print(f\"Dataset saved: {len(df)} entries in clutch_web_design_companies_large.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec99e9-6131-4d7c-9b7e-a16507ed915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¢ Fetching page 1...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "# API Configuration\n",
    "url = \"https://clutch-co-scraper1.p.rapidapi.com/\"\n",
    "headers = {\n",
    "    \"x-rapidapi-key\": \"29176455d0msh76cff296476b1c5p160124jsn18fe314a32b4\",\n",
    "    \"x-rapidapi-host\": \"clutch-co-scraper1.p.rapidapi.com\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# CSV File Setup\n",
    "csv_filename = \"clutch_web_design_companies_large.csv\"\n",
    "fields = [\"Company Name\", \"Location\", \"Rating\", \"Reviews\", \"Website\", \"Hourly Rate\", \"Employees\", \"Services\"]\n",
    "\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(fields)\n",
    "\n",
    "    page = 1\n",
    "    total_entries = 0\n",
    "\n",
    "    while True:\n",
    "        print(f\"üì¢ Fetching page {page}...\")\n",
    "\n",
    "        # API Request\n",
    "        payload = {\"api_type\": \"search\", \"search_term\": \"web design\", \"page\": str(page)}\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error: {response.status_code}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # üõ†Ô∏è Debug: Print response format on first page\n",
    "        if page == 1:\n",
    "            print(\"\\nüìå API Response (Page 1):\")\n",
    "            print(json.dumps(data, indent=2))  # Pretty print JSON\n",
    "\n",
    "        # ‚úÖ Check if response is a dictionary with \"results\" key\n",
    "        if not isinstance(data, dict) or \"results\" not in data:\n",
    "            print(f\"‚ö†Ô∏è Unexpected response format on page {page}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        companies = data[\"results\"]\n",
    "\n",
    "        if not companies:  # If no more results\n",
    "            print(f\"‚úÖ No more data on page {page}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Extract & Save Data\n",
    "        for company in companies:\n",
    "            row = [\n",
    "                company.get(\"company_name\", \"N/A\"),\n",
    "                company.get(\"location\", \"N/A\"),\n",
    "                company.get(\"rating\", \"N/A\"),\n",
    "                company.get(\"reviews\", \"N/A\"),\n",
    "                company.get(\"website\", \"N/A\"),\n",
    "                company.get(\"hourly_rate\", \"N/A\"),\n",
    "                company.get(\"employees\", \"N/A\"),\n",
    "                \", \".join(company.get(\"services\", [])) if isinstance(company.get(\"services\"), list) else \"N/A\"\n",
    "            ]\n",
    "            writer.writerow(row)\n",
    "            total_entries += 1\n",
    "\n",
    "        print(f\"‚úÖ Page {page} processed. Total entries so far: {total_entries}\")\n",
    "\n",
    "        page += 1  # Move to next page\n",
    "        time.sleep(2)  # Avoid rate-limiting (adjust if needed)\n",
    "\n",
    "print(f\"\\nüéâ Dataset saved: {total_entries} entries in {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dbbaf-7b7d-4045-b03c-03fea41fc521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
